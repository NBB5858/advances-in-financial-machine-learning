{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede945a6-1b59-40b0-89bf-a641a2de9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.stattools import kpss, adfuller\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from numpy.random import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a03c8c9-c9ce-477b-9537-0af6f40035db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AFML_module.dataset_utilities import (get_instrument_attributes, \n",
    "                                           form_dollar_bars, \n",
    "                                           form_time_bars,\n",
    "                                           form_vol_bars,\n",
    "                                           reduce_to_active_symbols, \n",
    "                                           apply_roll_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60680418-a593-4593-a287-f8cb3b465ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-01 23:53:17.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mAFML_module.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/noahbittermann/PycharmProjects/advances-in-financial-machine-learning\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Credit risk data from Kaggle. # Ground truth is whether individual has defaulted\n",
    "# https://www.kaggle.com/datasets/adilshamim8/credit-risk-benchmark-dataset\n",
    "\n",
    "from AFML_module.config import RAW_DATA_DIR\n",
    "\n",
    "data = pd.read_csv(RAW_DATA_DIR/\"Credit Risk Benchmark Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1294243e-f9bb-49fe-9d87-6e7914711884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_util</th>\n",
       "      <th>age</th>\n",
       "      <th>late_30_59</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>monthly_inc</th>\n",
       "      <th>open_credit</th>\n",
       "      <th>late_90</th>\n",
       "      <th>real_estate</th>\n",
       "      <th>late_60_89</th>\n",
       "      <th>dependents</th>\n",
       "      <th>dlq_2yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006999</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302150</td>\n",
       "      <td>5440.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.704592</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471441</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063113</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068586</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.368397</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296273</td>\n",
       "      <td>6250.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_util   age  late_30_59  debt_ratio  monthly_inc  open_credit  late_90  \\\n",
       "0  0.006999  38.0         0.0    0.302150       5440.0          4.0      0.0   \n",
       "1  0.704592  63.0         0.0    0.471441       8000.0          9.0      0.0   \n",
       "2  0.063113  57.0         0.0    0.068586       5000.0         17.0      0.0   \n",
       "3  0.368397  68.0         0.0    0.296273       6250.0         16.0      0.0   \n",
       "4  1.000000  34.0         1.0    0.000000       3500.0          0.0      0.0   \n",
       "\n",
       "   real_estate  late_60_89  dependents  dlq_2yrs  \n",
       "0          1.0         0.0         3.0         0  \n",
       "1          1.0         0.0         0.0         0  \n",
       "2          0.0         0.0         0.0         0  \n",
       "3          2.0         0.0         0.0         0  \n",
       "4          0.0         0.0         1.0         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf9c45-eda3-4bc9-95dc-7e8b10f53fe1",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c645cea-1ce7-4c5f-a6f1-1de0949251be",
   "metadata": {},
   "source": [
    "### 6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8a68f-e63c-4bfb-a143-013fdc23c395",
   "metadata": {},
   "source": [
    "Why is bagging based on random sampling with replacement? Would bagging\n",
    "still reduce a forecastâ€™s variance if sampling were without replacement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69ac2a-2c4e-4381-9f22-4684edcdc95e",
   "metadata": {},
   "source": [
    "The goal of bagging is to reduce variance by averaging together forecasts fromm models trained on bootstrapped datasets.  However, it is not effective if the forecasts from the different models are highly correlated.\n",
    "\n",
    "Suppose we sample $m$ datapoints from an original sample of $n$. If $n=m$, then all our bootstrapped dateasets are identical, and the model forecasts will have a correlation of 1.  Moreover, the bootstrapped datasets will remain very similar even as we decrease $m$ (For example, if I have 10 samples to resample from, drawing 7 samples without replacement will yield training datasets that are practically the same, so the forecasts will be highly correlated).  If we continue to decrease $m$ to lessen this effect, then we being to sacrifice accuracy, since each model is only trained on a very small fraction of the original dataset. Therefore, sampling should be done with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e161f-f7af-4779-b1dd-8c578480be00",
   "metadata": {},
   "source": [
    "### 6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01bd46-a5aa-4580-8f52-ec38002d6788",
   "metadata": {},
   "source": [
    "Suppose that your training set is based on highly overlap labels (i.e., with low\n",
    "uniqueness, as defined in Chapter 4).\n",
    "\n",
    "(a) Does this make bagging prone to overfitting, or just ineffective? Why?\n",
    "\n",
    "(b) Is out-of-bag accuracy generally reliable in financial applications? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928947f5-10ab-4168-b60f-0f2780b29b80",
   "metadata": {},
   "source": [
    "(a) As shown in the text, the bagged estimator cannot increase the variance _compared to a single estimator_.  Therefore, it will not lead to overfitting.  However it can be ineffective if the correlation of forecasts is near 1, which is the case if the estimators are trained on very similar resampled datasets.  This occurs if there is a high degree of observational redundancy in the original dataset.  \n",
    "\n",
    "One should also note that the variance of a single estimator will increase if the samples are not IID.\n",
    "\n",
    "(b) OOB accuracy is not reliable in finance, because samples are not typically IID.  Because we cannot resample independently, the data in the bag will be very similar to that out of the bag. Specifically, the same information is partially determining both the in and out of bag data, which constitues data leakage. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1932a2c-fee2-4f22-bc02-077485a922dd",
   "metadata": {},
   "source": [
    "### 6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39192e09-2d5f-4ff0-ae72-3d1d9789c3ae",
   "metadata": {},
   "source": [
    "Build an ensemble of estimators, where the base estimator is a decision tree.\n",
    "\n",
    "(a) How is this ensemble different from an RF?\n",
    "\n",
    "(b) Using sklearn, produce a bagging classifier that behaves like an RF. What\n",
    "parameters did you have to set up, and how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba31b232-c0b9-4ead-8464-95e7b9aa4c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Sample Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.87      2536\n",
      "           1       0.90      0.83      0.86      2478\n",
      "\n",
      "    accuracy                           0.87      5014\n",
      "   macro avg       0.87      0.87      0.87      5014\n",
      "weighted avg       0.87      0.87      0.87      5014\n",
      "\n",
      "Out of Sample Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      5821\n",
      "           1       0.79      0.73      0.76      5879\n",
      "\n",
      "    accuracy                           0.76     11700\n",
      "   macro avg       0.77      0.76      0.76     11700\n",
      "weighted avg       0.77      0.76      0.76     11700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build an ensemble of estimators where the base is a decision tree\n",
    "X = data[data.columns[:-1]]\n",
    "y = data[\"dlq_2yrs\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=0)\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=10)\n",
    "clf_bagged = BaggingClassifier(estimator=clf_tree, n_estimators=100, max_samples=1.0)\n",
    "\n",
    "clf_bagged.fit(X_train, y_train)\n",
    "\n",
    "print(\"In Sample Results\")\n",
    "print(classification_report(y_train, clf_bagged.predict(X_train)))\n",
    "\n",
    "print(\"Out of Sample Results\")\n",
    "print(classification_report(y_test, clf_bagged.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d02d6-b177-4d94-b83d-6883ef971a8a",
   "metadata": {},
   "source": [
    "This bagged classifier is not a random forest. To build a random forest model, we must omit a subset of features at each node. We would change the max_features parameter to control this, as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4340ae4f-9c22-4ccd-9ea0-b7b1e7fb540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Sample Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89      2536\n",
      "           1       0.91      0.83      0.87      2478\n",
      "\n",
      "    accuracy                           0.88      5014\n",
      "   macro avg       0.88      0.88      0.88      5014\n",
      "weighted avg       0.88      0.88      0.88      5014\n",
      "\n",
      "Out of Sample Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      5821\n",
      "           1       0.80      0.73      0.76      5879\n",
      "\n",
      "    accuracy                           0.77     11700\n",
      "   macro avg       0.77      0.77      0.77     11700\n",
      "weighted avg       0.77      0.77      0.77     11700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=10)\n",
    "clf_boost = BaggingClassifier(estimator=clf_tree, n_estimators=100, max_samples=1.0, max_features=0.7)\n",
    "\n",
    "clf_boost.fit(X_train, y_train)\n",
    "\n",
    "print(\"In Sample Results\")\n",
    "print(classification_report(y_train, clf_boost.predict(X_train)))\n",
    "\n",
    "print(\"Out of Sample Results\")\n",
    "print(classification_report(y_test, clf_boost.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada60f6-a0e8-46fb-bd96-5b3cc7b2b159",
   "metadata": {},
   "source": [
    "### 6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dddf363-41bc-4da5-949a-836b8a86ce67",
   "metadata": {},
   "source": [
    "Consider the relation between an RF, the number of trees it is composed of, and\n",
    "the number of features utilized:\n",
    "\n",
    "(a) Could you envision a relation between the minimum number of trees needed\n",
    "in an RF and the number of features utilized?\n",
    "\n",
    "(b) Could the number of trees be too small for the number of features used?\n",
    "\n",
    "(c) Could the number of trees be too high for the number of observations available?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249c337-dbab-42e3-83de-ea352c82f021",
   "metadata": {},
   "source": [
    "(a), (b) If there are too few trees, then it is possible certain features will never be considered for splitting. For simplicity, we focus on trees that only have one splitting each. If there are $N$ total features and we consider $M$ in a split, then the probability of a feature being considered by the split is $$ P(\\text{Considered by Tree}) =  \\frac{M}{N}.$$\n",
    "If there are T trees, then the probability of never considering say feature $i$ is \n",
    "$$ P(\\text{Feature i Never Considered}) =  \\Big(1 - \\frac{M}{N}\\Big)^T.$$\n",
    "Now we want the probability that all features are considered at least once.  This is complicated by the fact that feature $i$ being considered is not independent of feature $j$ being considered. However, if $M \\sim< N$, then this effect is reduced; considering feature $i$ doesn't affect whether we consider feature $j$ all that much, because we still have many chances to pick $j$. In this approximation, we have       \n",
    "\n",
    "$$ P(\\text{All Features Considered at Least Once}) \\approx  \\Big(1- \\Big(1 - \\frac{M}{N}\\Big)^T\\Big)^N \\approx 1 - N\\Big(1 - \\frac{M}{N}\\Big)^T > p.$$\n",
    "\n",
    "Solving for $T$, we find $$ T > \\frac{\\log(\\frac{1 - p}{n})}{\\log(1 - \\frac{m}{n})}$$ \n",
    "\n",
    "For e.g. $N = 20$, $M = 10$, $p=0.99$, we find $T >\\sim 10$. The minimum value of $T$ will also be higher if we account for the fact that considering features is not independent.\n",
    "\n",
    "(c) There is no harm in overfitting due to increasing the number of trees relative to the number of observations. However, there will be diminishing returns to doing so, especially if the correlation of predictions are high  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026be0e4-7a56-42c5-8ad7-cf9944a925fd",
   "metadata": {},
   "source": [
    "### 6.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed200f2c-0f86-4a72-9d39-ad2bebbe3e0e",
   "metadata": {},
   "source": [
    "How is out-of-bag accuracy different from stratified k-fold (with shuffling) crossvalidation accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c70421-c009-4562-add7-c89a7eda309a",
   "metadata": {},
   "source": [
    "Actually, they're both similar in that they artifically inflate OOS accuracy of the model. In the case of OOB accuracy, if the samples are not IID, then the bootstrapped training sets will have information overlap with the OOB test set.  This constitutes data leakage. \n",
    "\n",
    "The same thing happens for k fold cross validation __with__ shuffling.  If the sampling is not IID, then labels that are the result of overlapping information will be spread across the training sets and the validation sets, again leading to data leakage. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
